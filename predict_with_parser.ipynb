{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Graph function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import Node\n",
    "\n",
    "def construct_graph(command_list, command_dict={}):\n",
    "\n",
    "    filter_empty = lambda x: (len(x) > 0)\n",
    "    cur_node = None\n",
    "    child_node = None\n",
    "    \n",
    "    for session in command_list:\n",
    "        # remove commands of length 0 ( not good to modify list within loop )\n",
    "        \n",
    "        session = list(filter(filter_empty, session))\n",
    "\n",
    "        try: \n",
    "            first_cmd = session[0]\n",
    "        except Exception as inst:\n",
    "            print(session)\n",
    "            continue\n",
    "\n",
    "        program = session[0].split()[0]\n",
    "\n",
    "        if command_dict.get(program) is None:\n",
    "            cur_node = Node(program=program, frequency=1)\n",
    "            command_dict[program] = cur_node \n",
    "        else:\n",
    "            cur_node = command_dict.get(program)\n",
    "            cur_node.frequency += 1\n",
    "\n",
    "        if cur_node.commands.get(first_cmd) is None:\n",
    "            cur_node.commands[first_cmd] = 1\n",
    "        else:\n",
    "            cur_node.commands[first_cmd] += 1\n",
    "\n",
    "        for cmd in range(1, len(session)):\n",
    "\n",
    "            if session[cmd].isprintable() is False:\n",
    "                break\n",
    "            else:\n",
    "                program = session[cmd].split()[0]\n",
    "\n",
    "            if cur_node.children.get(program) is None:\n",
    "                child_node = Node(program = program, frequency=1)\n",
    "                cur_node.children[program] = child_node\n",
    "            else:\n",
    "                child_node = cur_node.children.get(program)\n",
    "                child_node.frequency += 1\n",
    "            \n",
    "            if child_node.commands.get(session[cmd]) is None:\n",
    "                child_node.commands[session[cmd]] = 1\n",
    "            else:\n",
    "                child_node.commands[session[cmd]] += 1\n",
    "            \n",
    "            cur_node = child_node\n",
    "        \n",
    "                \n",
    "        \n",
    "    return command_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(command_list, graph, result_size=5):\n",
    "    if len(command_list) == 0:\n",
    "        return None\n",
    "\n",
    "    commands = command_list[-3:-1]\n",
    "    previous_command = command_list[-1]\n",
    "\n",
    "    if len(commands) == 0:\n",
    "        return None\n",
    "\n",
    "    program = commands[0].split()[0]\n",
    "    \n",
    "    if graph.get(program) is None:\n",
    "        return None\n",
    "    else:\n",
    "        node = graph[program]\n",
    "\n",
    "    for command in commands[1:]:\n",
    "        program = command.split()[0]\n",
    "        if node.children.get(program) is not None:\n",
    "            node = node.children[program]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    return node.get_prediction(previous_command, num_to_return=result_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def append_list(lst, results, commands):\n",
    "    # lst.append((\"results:\", results, \"expected:\", commands[-1], \"command sequence:\", commands))\n",
    "    lst.append({\"Results\": results, \"Expected\": commands[-1], \"Command Sequence\": commands})\n",
    "\n",
    "def get_accuracy(command_subsets, fail_list = [], succeed_list = [], correct_15_not_5 = [], print_fails = False):\n",
    "    train_data, test_data = train_test_split(command_subsets, test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "    train_graph = construct_graph(train_data)\n",
    "\n",
    "    test_size = len(test_data)\n",
    "\n",
    "    return_5 = 5\n",
    "    return_15 = 15\n",
    "\n",
    "    correct = 0\n",
    "    correct_with_15 = 0\n",
    "    first_prediction = 0\n",
    "    has_prediction = 0\n",
    "    incorrect = 0\n",
    "    none_count = 0\n",
    "\n",
    "    for commands in test_data:\n",
    "        results = get_prediction(commands, train_graph, return_5)\n",
    "        results_15 = get_prediction(commands, train_graph, return_15)\n",
    "        \n",
    "        prev_correct = correct\n",
    "\n",
    "        if results is not None:\n",
    "            has_prediction += 1\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                if fuzz.ratio(results[i][0], commands[-1]) > 90:\n",
    "                    correct += 1\n",
    "\n",
    "                    if i == 0:\n",
    "                        first_prediction += 1\n",
    "\n",
    "                    if correct <= 100:\n",
    "                        append_list(succeed_list, results, commands)\n",
    "\n",
    "                    break\n",
    "\n",
    "            if prev_correct == correct:\n",
    "                incorrect += 1\n",
    "\n",
    "            for i in range(len(results_15)):\n",
    "                if fuzz.ratio(results_15[i][0], commands[-1]) > 90:\n",
    "                    correct_with_15 += 1\n",
    "\n",
    "                    if correct != correct_with_15:\n",
    "                        append_list(correct_15_not_5, results_15, commands)\n",
    "\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "        if prev_correct == correct and print_fails:\n",
    "            append_list(fail_list, results, commands)                    \n",
    "\n",
    "    return 'Correct Proportion: {:.2f}% |\\n Correct in 15 not 5: {:.2f}% |\\n Has Prediction and is Correct: {:.2f}% |\\n Incorrect Proportion: {:.2f}% |\\n None Proportion: {:.2f}% |\\n First Prediction: {:.2f}%'.format(100 * correct/test_size, 100 * correct_with_15/test_size, 100 * correct/has_prediction, 100 * incorrect/test_size, 100 * none_count/test_size, 100 * first_prediction/test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:10<00:00,  5.11it/s]\n",
      "100%|██████████| 36/36 [00:05<00:00,  6.35it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.81it/s]\n",
      "100%|██████████| 56/56 [00:06<00:00,  8.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from parse import Parser\n",
    "\n",
    "parser = Parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nold, returning all potential commands - args not replaced\\n\\n91.19%\\n96.35%\\n90.31%\\n93.18%\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science = parser.filter_commands_with_pipe(parser.scientists_commands)\n",
    "experienced = parser.filter_commands_with_pipe(parser.experienced_commands)\n",
    "non = parser.filter_commands_with_pipe(parser.non_programmers_commands)\n",
    "novice = parser.filter_commands_with_pipe(parser.novice_commands)\n",
    "\n",
    "science_pipes = parser.expand_piped_commands(science)\n",
    "experienced_pipes = parser.expand_piped_commands(experienced)\n",
    "non_pipes = parser.expand_piped_commands(non)\n",
    "novice_pipes = parser.expand_piped_commands(novice)\n",
    "\n",
    "science_pipes_expand = parser.replace_arg_expanded_pipe(science_pipes)\n",
    "experienced_pipes_expand = parser.replace_arg_expanded_pipe(experienced_pipes)\n",
    "non_pipes_expand = parser.replace_arg_expanded_pipe(non_pipes)\n",
    "novice_pipes_expand = parser.replace_arg_expanded_pipe(novice_pipes)\n",
    "\n",
    "# print(get_accuracy(science_pipes))\n",
    "# print(get_accuracy(experienced_pipes))\n",
    "# print(get_accuracy(non_pipes))\n",
    "# print(get_accuracy(novice_pipes))\n",
    "\n",
    "\"\"\"\n",
    "old, returning all potential commands - args not replaced\n",
    "\n",
    "91.19%\n",
    "96.35%\n",
    "90.31%\n",
    "93.18%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Science pipes metrics:\n",
      " Correct Proportion: 58.07% |\n",
      " Correct in 15 not 5: 67.51% |\n",
      " Has Prediction and is Correct: 59.19% |\n",
      " Incorrect Proportion: 40.04% |\n",
      " None Proportion: 1.89% |\n",
      " First Prediction: 38.78% \n",
      "\n",
      "Experienced pipes metrics:\n",
      " Correct Proportion: 73.06% |\n",
      " Correct in 15 not 5: 86.76% |\n",
      " Has Prediction and is Correct: 73.73% |\n",
      " Incorrect Proportion: 26.03% |\n",
      " None Proportion: 0.91% |\n",
      " First Prediction: 48.40% \n",
      "\n",
      "Non programmers pipes metrics:\n",
      " Correct Proportion: 73.26% |\n",
      " Correct in 15 not 5: 80.43% |\n",
      " Has Prediction and is Correct: 77.30% |\n",
      " Incorrect Proportion: 21.51% |\n",
      " None Proportion: 5.23% |\n",
      " First Prediction: 58.72% \n",
      "\n",
      "Novice pipes metrics:\n",
      " Correct Proportion: 47.73% |\n",
      " Correct in 15 not 5: 70.45% |\n",
      " Has Prediction and is Correct: 47.73% |\n",
      " Incorrect Proportion: 52.27% |\n",
      " None Proportion: 0.00% |\n",
      " First Prediction: 25.00% \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFuzzy match ratio == 90\\n\\nCorrect Proportion: 54.09% | Has Prediction and is Correct: 55.13% | Incorrect Proportion: 44.03% | None Proportion: 1.89% | First Prediction: 37.11%\\nCorrect Proportion: 69.86% | Has Prediction and is Correct: 70.51% | Incorrect Proportion: 29.22% | None Proportion: 0.91% | First Prediction: 54.79%\\nCorrect Proportion: 73.06% | Has Prediction and is Correct: 77.10% | Incorrect Proportion: 21.71% | None Proportion: 5.23% | First Prediction: 58.72%\\nCorrect Proportion: 25.00% | Has Prediction and is Correct: 25.00% | Incorrect Proportion: 75.00% | None Proportion: 0.00% | First Prediction: 25.00%\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Science pipes metrics:\\n\", get_accuracy(science_pipes_expand), \"\\n\")\n",
    "print(\"Experienced pipes metrics:\\n\", get_accuracy(experienced_pipes_expand), \"\\n\")\n",
    "print(\"Non programmers pipes metrics:\\n\", get_accuracy(non_pipes_expand), \"\\n\")\n",
    "print(\"Novice pipes metrics:\\n\", get_accuracy(novice_pipes_expand), \"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Fuzzy match ratio == 90\n",
    "\n",
    "Correct Proportion: 54.09% | Has Prediction and is Correct: 55.13% | Incorrect Proportion: 44.03% | None Proportion: 1.89% | First Prediction: 37.11%\n",
    "Correct Proportion: 69.86% | Has Prediction and is Correct: 70.51% | Incorrect Proportion: 29.22% | None Proportion: 0.91% | First Prediction: 54.79%\n",
    "Correct Proportion: 73.06% | Has Prediction and is Correct: 77.10% | Incorrect Proportion: 21.71% | None Proportion: 5.23% | First Prediction: 58.72%\n",
    "Correct Proportion: 25.00% | Has Prediction and is Correct: 25.00% | Incorrect Proportion: 75.00% | None Proportion: 0.00% | First Prediction: 25.00%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 5\n",
    "\n",
    "science_replaced = parser.replace_args(parser.scientists_commands)\n",
    "science_replaced = parser.parse_commands_into_subsets(science_replaced, subset_size)\n",
    "\n",
    "experienced_replaced = parser.replace_args(parser.experienced_commands)\n",
    "experienced_replaced = parser.parse_commands_into_subsets(experienced_replaced, subset_size)\n",
    "\n",
    "non_replaced = parser.replace_args(parser.non_programmers_commands)\n",
    "non_replaced = parser.parse_commands_into_subsets(non_replaced, subset_size)\n",
    "\n",
    "novice_replaced = parser.replace_args(parser.novice_commands)\n",
    "novice_replaced = parser.parse_commands_into_subsets(novice_replaced, subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist replaced:\n",
      " Correct Proportion: 81.62% |\n",
      " Correct in 15 not 5: 89.69% |\n",
      " Has Prediction and is Correct: 82.69% |\n",
      " Incorrect Proportion: 17.08% |\n",
      " None Proportion: 1.30% |\n",
      " First Prediction: 58.42%\n",
      "Experienced replaced:\n",
      " Correct Proportion: 83.80% |\n",
      " Correct in 15 not 5: 90.88% |\n",
      " Has Prediction and is Correct: 85.02% |\n",
      " Incorrect Proportion: 14.77% |\n",
      " None Proportion: 1.44% |\n",
      " First Prediction: 61.64%\n",
      "Non programmer replaced:\n",
      " Correct Proportion: 85.02% |\n",
      " Correct in 15 not 5: 92.22% |\n",
      " Has Prediction and is Correct: 85.75% |\n",
      " Incorrect Proportion: 14.13% |\n",
      " None Proportion: 0.85% |\n",
      " First Prediction: 59.97%\n",
      "Novice replaced:\n",
      " Correct Proportion: 88.03% |\n",
      " Correct in 15 not 5: 94.16% |\n",
      " Has Prediction and is Correct: 89.08% |\n",
      " Incorrect Proportion: 10.79% |\n",
      " None Proportion: 1.18% |\n",
      " First Prediction: 64.15%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFuzz ratio == 90\\n\\nScientist replaced:\\n Correct Proportion: 81.90% | Has Prediction and is Correct: 82.97% | Incorrect Proportion: 16.81% | None Proportion: 1.30% | First Prediction: 58.64%\\nExperienced replaced:\\n Correct Proportion: 83.89% | Has Prediction and is Correct: 85.11% | Incorrect Proportion: 14.68% | None Proportion: 1.44% | First Prediction: 61.73%\\nNon programmer replaced:\\n Correct Proportion: 85.04% | Has Prediction and is Correct: 85.77% | Incorrect Proportion: 14.11% | None Proportion: 0.85% | First Prediction: 60.01%\\nNovice replaced:\\n Correct Proportion: 88.03% | Has Prediction and is Correct: 89.08% | Incorrect Proportion: 10.79% | None Proportion: 1.18% | First Prediction: 64.17%\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Scientist replaced:\\n\", get_accuracy(science_replaced))\n",
    "print(\"Experienced replaced:\\n\", get_accuracy(experienced_replaced))\n",
    "print(\"Non programmer replaced:\\n\", get_accuracy(non_replaced))\n",
    "print(\"Novice replaced:\\n\", get_accuracy(novice_replaced))\n",
    "\n",
    "\"\"\"\n",
    "Fuzz ratio == 90\n",
    "\n",
    "Scientist replaced:\n",
    " Correct Proportion: 81.90% | Has Prediction and is Correct: 82.97% | Incorrect Proportion: 16.81% | None Proportion: 1.30% | First Prediction: 58.64%\n",
    "Experienced replaced:\n",
    " Correct Proportion: 83.89% | Has Prediction and is Correct: 85.11% | Incorrect Proportion: 14.68% | None Proportion: 1.44% | First Prediction: 61.73%\n",
    "Non programmer replaced:\n",
    " Correct Proportion: 85.04% | Has Prediction and is Correct: 85.77% | Incorrect Proportion: 14.11% | None Proportion: 0.85% | First Prediction: 60.01%\n",
    "Novice replaced:\n",
    " Correct Proportion: 88.03% | Has Prediction and is Correct: 89.08% | Incorrect Proportion: 10.79% | None Proportion: 1.18% | First Prediction: 64.17%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save not matching or none result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:32<00:29,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:33<00:00,  4.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "dataset_names = [\"Scientist replaced\", \"Experienced replaced\", \"Non programmer replaced\", \"Novice replaced\", \"Scientist pipes replaced\", \"Experienced pipes replaced\",\"Non programmer pipes replaced\", \"Novice pipes replaced\"]\n",
    "datasets = [science_replaced, experienced_replaced, non_replaced, novice_replaced, science_pipes_expand, experienced_pipes_expand, non_pipes_expand, novice_pipes_expand]\n",
    "\n",
    "for i in tqdm(range(len(datasets))):\n",
    "    fail_list = []\n",
    "    succeed_list = []\n",
    "    correct_15_not_5 = []\n",
    "\n",
    "    get_accuracy(datasets[i], fail_list=fail_list, succeed_list=succeed_list, correct_15_not_5=correct_15_not_5, print_fails=True)\n",
    "\n",
    "    with open(\"./fails/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "        file_object.write(pp.pformat(fail_list))\n",
    "    \n",
    "    with open(\"./successes/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "        file_object.write(pp.pformat(succeed_list))\n",
    "\n",
    "    with open(\"./correct_with_15/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "        file_object.write(pp.pformat(correct_15_not_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training graphs to JSON files. Files are 48.9 MB and very hard to open.\n",
    "\n",
    "Instead of this, we can just save it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "dataset_names = [\"Scientist replaced\", \"Experienced replaced\", \"Non programmer replaced\", \"Novice replaced\", \"Scientist pipes replaced\", \"Experienced pipes replaced\",\"Non programmer pipes replaced\", \"Novice pipes replaced\"]\n",
    "datasets = [science_replaced, experienced_replaced, non_replaced, novice_replaced, science_pipes_expand, experienced_pipes_expand, non_pipes_expand, novice_pipes_expand]\n",
    "\n",
    "train_graphs = []\n",
    "test_graphs = []\n",
    "\n",
    "# for i in tqdm(range(len(datasets))):\n",
    "#     train_data, test_data = train_test_split(datasets[i], test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "#     train_graph = construct_graph(train_data)\n",
    "#     test_graph = construct_graph(test_data)\n",
    "\n",
    "#     train_graphs.append(train_graph)\n",
    "#     test_graphs.append(test_graph)\n",
    "\n",
    "#     train_object = jsonpickle.encode(train_graph)\n",
    "#     test_object = jsonpickle.encode(test_graph)\n",
    "\n",
    "#     with open(\"./train_graphs/\" + dataset_names[i] + \" train.json\", \"w\") as file_object:\n",
    "#         file_object.write(train_object)\n",
    "\n",
    "#     with open (\"./test_graphs/\" + dataset_names[i] + \" test.json\", \"w\") as file_object:\n",
    "#         file_object.write(test_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "all = []\n",
    "\n",
    "# don't run this, it'll destroy the computer\n",
    "# for comb in itertools.combinations(parser.parse_commands_into_subsets(parser.novice_commands, 5), 5):\n",
    "#     all.append(list(comb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.getsizeof(parser.scientists_commands[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
