{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bashlex\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_command_filter = \"C\"\n",
    "re_error_filter = \"X\"\n",
    "re_start_filter = \"S\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientists_dir = \"./unix-data/computer-scientists/\"\n",
    "experienced_dir = \"./unix-data/experienced-programmers/\"\n",
    "non_programmers_dir = \"./unix-data/non-programmers/\"\n",
    "novice_dir = \"./unix-data/novice-programmers/\"\n",
    "\n",
    "scientists_files = os.listdir(scientists_dir)\n",
    "experienced_files = os.listdir(experienced_dir)\n",
    "non_programmers_files = os.listdir(non_programmers_dir)\n",
    "novice_files = os.listdir(novice_dir)\n",
    "\n",
    "scientist_commands = []\n",
    "experienced_commands = []\n",
    "non_programmers_commands = []\n",
    "novice_commands = []\n",
    "\n",
    "scientist_parsed = []\n",
    "experienced_parsed = []\n",
    "non_programmers_parsed = []\n",
    "novice_parsed = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(scientists_files)):\n",
    "    scientists_files[i] = scientists_dir + scientists_files[i]\n",
    "\n",
    "for i in range(len(experienced_files)):\n",
    "    experienced_files[i] = experienced_dir + experienced_files[i]\n",
    "\n",
    "for i in range(len(non_programmers_files)):\n",
    "    non_programmers_files[i] = non_programmers_dir + non_programmers_files[i]\n",
    "\n",
    "for i in range(len(novice_files)):\n",
    "    novice_files[i] = novice_dir + novice_files[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse function that returns nested list of parsed commands based on session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_commands_per_session(command_list, parsed_list, files_list):\n",
    "    for file_path in tqdm(files_list):\n",
    "        file1 = open(file_path, encoding=\"ISO-8859-1\")\n",
    "        lines = file1.readlines()\n",
    "\n",
    "        command_sublist = []\n",
    "        parsed_sublist = []\n",
    "\n",
    "        for line in range(len(lines)):\n",
    "            \n",
    "            if re.match(re_start_filter, lines[line]) is not None:\n",
    "                if len(command_sublist) != 0 and len(parsed_sublist) != 0:\n",
    "                    command_list.append(copy.deepcopy(command_sublist))\n",
    "                    parsed_list.append(copy.deepcopy(parsed_sublist))\n",
    "\n",
    "\n",
    "                command_sublist = []\n",
    "                parsed_sublist = []\n",
    "            \n",
    "            if re.match(re_command_filter, lines[line]) is not None:\n",
    "                command_sublist.append(lines[line][2:-1])\n",
    "                \n",
    "                try:\n",
    "                    parts = list(bashlex.split(command_sublist[-1]))\n",
    "                    parsed_sublist.append(parts)\n",
    "                except Exception as inst:\n",
    "                    command_sublist.pop(-1)\n",
    "                    \n",
    "    \n",
    "    # Not necessary as list is created by ref parameter \n",
    "    return command_list\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that parses just by command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_commands(command_list, parsed_list, files_list):\n",
    "    for file_path in tqdm(files_list): \n",
    "        file1 = open(file_path, encoding=\"ISO-8859-1\")\n",
    "        lines = file1.readlines()\n",
    "\n",
    "        for line in range(len(lines)):\n",
    "            if re.match(re_command_filter, lines[line]) is not None:\n",
    "                command_list.append(lines[line][2:-1])\n",
    "                \n",
    "                try:\n",
    "                    parts = bashlex.parse(command_list[-1])\n",
    "                    parsed_list.append(parts)\n",
    "                except Exception as inst:\n",
    "                    command_list.pop(-1)\n",
    "\n",
    "    return command_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that parses commands and groups into subsets of `subset_size` meaning command chains are `subset_size` commands long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_commands_into_subsets(command_list, parsed_list, files_list, subset_size):\n",
    "    command_list = copy.deepcopy(parse_commands(command_list, parsed_list, files_list))\n",
    "\n",
    "    filter_escaped = lambda x: (x and x.isprintable())\n",
    "    command_list = list(filter(filter_escaped, command_list))\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range(0, len(command_list), subset_size):\n",
    "        result.append(command_list[i:i+subset_size])\n",
    "\n",
    "    command_list = result\n",
    "\n",
    "    return command_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:09<00:00,  5.61it/s]\n",
      "100%|██████████| 36/36 [00:05<00:00,  7.13it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.90it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00,  9.47it/s]\n"
     ]
    }
   ],
   "source": [
    "scientist_commands = []\n",
    "experienced_commands = []\n",
    "non_programmers_commands = []\n",
    "novice_commands = []\n",
    "\n",
    "scientist_commands = parse_commands_per_session(scientist_commands, scientist_parsed, scientists_files)\n",
    "experienced_commands = parse_commands_per_session(experienced_commands, experienced_parsed, experienced_files)\n",
    "non_programmers_commands = parse_commands_per_session(non_programmers_commands, non_programmers_parsed, non_programmers_files)\n",
    "novice_commands = parse_commands_per_session(novice_commands, novice_parsed, novice_files)\n",
    "\n",
    "filter_empty = lambda x: (len(x) > 0)\n",
    "\n",
    "scientist_commands = list(filter(filter_empty, scientist_commands))\n",
    "experienced_commands = list(filter(filter_empty, experienced_commands))\n",
    "non_programmers_commands = list(filter(filter_empty, non_programmers_commands))\n",
    "novice_commands = list(filter(filter_empty, novice_commands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:10<00:00,  4.90it/s]\n",
      "100%|██████████| 36/36 [00:05<00:00,  6.08it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.88it/s]\n",
      "100%|██████████| 56/56 [00:06<00:00,  8.14it/s]\n"
     ]
    }
   ],
   "source": [
    "subset_size = 5\n",
    "\n",
    "scientist_commands = []\n",
    "experienced_commands = []\n",
    "non_programmers_commands = []\n",
    "novice_commands = []\n",
    "\n",
    "scientist_commands_subsets = parse_commands_into_subsets(scientist_commands, scientist_parsed, scientists_files, subset_size)\n",
    "experienced_commands_subsets = parse_commands_into_subsets(experienced_commands, experienced_parsed, experienced_files, subset_size)\n",
    "non_programmers_commands_subsets = parse_commands_into_subsets(non_programmers_commands, non_programmers_parsed, non_programmers_files, subset_size)\n",
    "novice_commands_subsets = parse_commands_into_subsets(novice_commands, novice_parsed, novice_files, subset_size)\n",
    "\n",
    "filter_empty = lambda x: (x is not None)\n",
    "\n",
    "scientist_commands_subsets = list(filter(filter_empty, scientist_commands_subsets))\n",
    "experienced_commands_subsets = list(filter(filter_empty, experienced_commands_subsets))\n",
    "non_programmers_commands_subsets = list(filter(filter_empty, non_programmers_commands_subsets))\n",
    "novice_commands_subsets = list(filter(filter_empty, novice_commands_subsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24925\n",
      "14790\n",
      "5076\n",
      "15336\n",
      "['ls', 'm ken', 'gc', 'ls -l', 'alias']\n"
     ]
    }
   ],
   "source": [
    "print(len(scientist_commands_subsets))\n",
    "print(len(experienced_commands_subsets))\n",
    "print(len(non_programmers_commands_subsets))\n",
    "print(len(novice_commands_subsets))\n",
    "\n",
    "print(scientist_commands_subsets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defunct, predicts next argument in command with this structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import Node\n",
    "\n",
    "def construct_graph_defunct(parsed_commands, command_dict = {}):\n",
    "\n",
    "    for cmd in parsed_commands:\n",
    "\n",
    "        cur_node = None\n",
    "\n",
    "        if command_dict.get(cmd[0]) is None:\n",
    "            cur_node = Node(command = cmd[0], frequency = 1)\n",
    "            command_dict[cmd[0]] = cur_node\n",
    "        else:\n",
    "            command_dict.get(cmd[0]).frequency += 1\n",
    "            cur_node = command_dict.get(cmd[0])\n",
    "\n",
    "        for i in range(1, len(cmd)):\n",
    "            child_node = None\n",
    "\n",
    "            if cur_node.children.get(cmd[i]) is None:\n",
    "                child_node = Node(cmd[i], 1)\n",
    "                cur_node.children[cmd[i]] = child_node\n",
    "            else:\n",
    "                cur_node.children.get(cmd[i]).frequency += 1\n",
    "                child_node = cur_node.children.get(cmd[i])\n",
    "            \n",
    "            cur_node = child_node\n",
    "        \n",
    "    return command_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph structure for next command. Use command list instead of bashlex output since we are comparing whole commands as nodes in a graph.\n",
    "\n",
    "Making command dict key the program (e.g. `cat`) and value the node with that program and have that nodes children be the full command. And then have the children of those nodes be determined by fuzzy matching. So a node can be a child to many parents if its fuzzy matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import Node\n",
    "\n",
    "def construct_graph(command_list, command_dict={}):\n",
    "\n",
    "    filter_empty = lambda x: (len(x) > 0)\n",
    "    cur_node = None\n",
    "    child_node = None\n",
    "    \n",
    "    for session in command_list:\n",
    "        # remove commands of length 0 ( not good to modify list within loop )\n",
    "        \n",
    "        session = list(filter(filter_empty, session))\n",
    "\n",
    "        first_cmd = session[0]\n",
    "\n",
    "        program = session[0].split()[0]\n",
    "\n",
    "        if command_dict.get(program) is None:\n",
    "            cur_node = Node(program=program, frequency=1)\n",
    "            command_dict[program] = cur_node \n",
    "        else:\n",
    "            cur_node = command_dict.get(program)\n",
    "            cur_node.frequency += 1\n",
    "\n",
    "        if cur_node.commands.get(first_cmd) is None:\n",
    "            cur_node.commands[first_cmd] = 1\n",
    "        else:\n",
    "            cur_node.commands[first_cmd] += 1\n",
    "\n",
    "        for cmd in range(1, len(session)):\n",
    "\n",
    "            if session[cmd].isprintable() is False:\n",
    "                break\n",
    "            else:\n",
    "                program = session[cmd].split()[0]\n",
    "\n",
    "            if cur_node.children.get(program) is None:\n",
    "                child_node = Node(program = program, frequency=1)\n",
    "                cur_node.children[program] = child_node\n",
    "            else:\n",
    "                child_node = cur_node.children.get(program)\n",
    "                child_node.frequency += 1\n",
    "            \n",
    "            if child_node.commands.get(session[cmd]) is None:\n",
    "                child_node.commands[session[cmd]] = 1\n",
    "            else:\n",
    "                child_node.commands[session[cmd]] += 1\n",
    "            \n",
    "            cur_node = child_node\n",
    "        \n",
    "                \n",
    "        \n",
    "    return command_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "scientist_graph = construct_graph(scientist_commands_subsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes list of commands and observes last 4 to predict 5th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(command_list, graph):\n",
    "    if len(command_list) == 0:\n",
    "        return None\n",
    "\n",
    "    commands = command_list[-5:-1]\n",
    "    previous_command = command_list[-1]\n",
    "\n",
    "    if len(commands) == 0:\n",
    "        return None\n",
    "\n",
    "    program = commands[0].split()[0]\n",
    "    \n",
    "    if graph.get(program) is None:\n",
    "        return None\n",
    "    else:\n",
    "        node = graph[program]\n",
    "\n",
    "    for command in commands[1:]:\n",
    "        program = command.split()[0]\n",
    "        if node.children.get(program) is not None:\n",
    "            node = node.children[program]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    return node.get_prediction(previous_command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(command_list, split_ratio):\n",
    "    test_data = command_list[int((len(command_list) + 1) * split_ratio):]\n",
    "    train_data = command_list[:int((len(command_list) + 1) * split_ratio)]\n",
    "\n",
    "    return test_data, train_data\n",
    "\n",
    "def get_accuracy(command_subsets):\n",
    "    split_ratio = .8\n",
    "    test_data, train_data = test_train_split(command_subsets, split_ratio)\n",
    "\n",
    "    train_graph = construct_graph(train_data)\n",
    "\n",
    "    test_size = len(test_data)\n",
    "    correct = 0\n",
    "\n",
    "    for commands in test_data:\n",
    "        result = get_prediction(commands, train_graph)\n",
    "        if result == commands[-1]:\n",
    "            correct += 1\n",
    "\n",
    "    return '{:.2f}%'.format(100 * correct/test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200\n",
      "100 202\n",
      "200 200\n",
      "300 200\n",
      "400 200\n",
      "500 200\n",
      "600 200\n",
      "700 200\n",
      "800 200\n",
      "900 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logs': [],\n",
       " 'activationId': 'b9b5f2e666ff4baab5f2e666ff5baa8e',\n",
       " 'code': '8bc652e1a1249e8aee42165b9859ddae',\n",
       " 'error': 'Response not yet ready.'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"https://us-south.functions.appdomain.cloud/api/v1/web/ORG-UNC-dist-seed-james_dev/cyverse/get-cyverse-log\"\n",
    "query = {'body': {'log_type':'Bash', 'password': 'password', 'skip': '0', 'limit':'100'}}\n",
    "\n",
    "response_dict = {}\n",
    "\n",
    "def get_cyverse_commands():\n",
    "    for i in range(0, 1000, 100):\n",
    "        query = {'body': {'log_type':'Bash', 'password': 'password', 'skip': str(i), 'limit':'100'}}\n",
    "        response = requests.get(url, headers = {\"Content-Type\": \"application/json\"}, json = query)\n",
    "        print(i, response.status_code)\n",
    "        response_dict.update(response.json())\n",
    "        time.sleep(50)\n",
    "\n",
    "    return response_dict\n",
    "\n",
    "get_cyverse_commands()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1388"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyverse_commands = []\n",
    "\n",
    "for log in response_dict['logs']:\n",
    "    for command in log['log']['commands']:\n",
    "        if 'full_command' in command:\n",
    "            cyverse_commands.append(command['full_command'])\n",
    "\n",
    "len(cyverse_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.09%'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_cyverse_subsets(command_list, subset_size):\n",
    "    result = []\n",
    "\n",
    "    for i in range(0, len(command_list), subset_size):\n",
    "        result.append(command_list[i:i+subset_size])\n",
    "\n",
    "    return result\n",
    "\n",
    "cyverse_commands_subsets = parse_cyverse_subsets(cyverse_commands, 5)\n",
    "\n",
    "get_accuracy(cyverse_commands_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientists accuracy: 84.43%\n",
      "Experienced accuracy: 91.24%\n",
      "Non programmers accuracy: 66.50%\n",
      "Novice programmers accuracy: 1.14%\n",
      "All data accuracy: 36.23%\n"
     ]
    }
   ],
   "source": [
    "print(\"Scientists accuracy:\", get_accuracy(scientist_commands_subsets))\n",
    "print(\"Experienced accuracy:\", get_accuracy(experienced_commands_subsets))\n",
    "print(\"Non programmers accuracy:\", get_accuracy(non_programmers_commands_subsets))\n",
    "print(\"Novice programmers accuracy:\", get_accuracy(novice_commands_subsets))\n",
    "\n",
    "all_data = scientist_commands_subsets + experienced_commands_subsets + non_programmers_commands_subsets + novice_commands_subsets\n",
    "\n",
    "print(\"All data accuracy:\", get_accuracy(all_data))\n",
    "\n",
    "#print(\"Cyverse accuracy\", get_accuracy(cyverse_commands_subsets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:08<00:00,  6.31it/s]\n",
      "100%|██████████| 36/36 [00:04<00:00,  7.95it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.09it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00, 10.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from parse import Parser\n",
    "\n",
    "parser = Parser()\n",
    "\n",
    "result = parser.parse_commands_into_subsets(parser.scientists_commands, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:08<00:00,  6.25it/s]\n",
      "100%|██████████| 36/36 [00:04<00:00,  8.00it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 12.74it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419 1109 2585 227\n",
      "cat pre cr31 cr31 | tbl | itroff -me &  nroff -me > kenout< foo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from parse import Parser\n",
    "\n",
    "parser = Parser()\n",
    "\n",
    "science = parser.filter_commands_with_pipe(parser.scientists_commands)\n",
    "experienced = parser.filter_commands_with_pipe(parser.experienced_commands)\n",
    "non = parser.filter_commands_with_pipe(parser.non_programmers_commands)\n",
    "novice = parser.filter_commands_with_pipe(parser.novice_commands)\n",
    "\n",
    "print(len(science), len(experienced), len(non), len(novice))\n",
    "science_pipes = parser.expand_piped_commands(science)\n",
    "print(science[1])\n",
    "print(science_pipes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat pre ken | nroff -me > kenout\n"
     ]
    }
   ],
   "source": [
    "print(science[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
