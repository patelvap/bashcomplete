{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bashlex\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_command_filter = \"C\"\n",
    "re_error_filter = \"X\"\n",
    "re_start_filter = \"S\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientists_dir = \"./unix-data/computer-scientists/\"\n",
    "experienced_dir = \"./unix-data/experienced-programmers/\"\n",
    "non_programmers_dir = \"./unix-data/non-programmers/\"\n",
    "novice_dir = \"./unix-data/novice-programmers/\"\n",
    "\n",
    "scientists_files = os.listdir(scientists_dir)\n",
    "experienced_files = os.listdir(experienced_dir)\n",
    "non_programmers_files = os.listdir(non_programmers_dir)\n",
    "novice_files = os.listdir(novice_dir)\n",
    "\n",
    "scientist_commands = []\n",
    "experienced_commands = []\n",
    "non_programmers_commands = []\n",
    "novice_commands = []\n",
    "\n",
    "scientist_parsed = []\n",
    "experienced_parsed = []\n",
    "non_programmers_parsed = []\n",
    "novice_parsed = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(scientists_files)):\n",
    "    scientists_files[i] = scientists_dir + scientists_files[i]\n",
    "\n",
    "for i in range(len(experienced_files)):\n",
    "    experienced_files[i] = experienced_dir + experienced_files[i]\n",
    "\n",
    "for i in range(len(non_programmers_files)):\n",
    "    non_programmers_files[i] = non_programmers_dir + non_programmers_files[i]\n",
    "\n",
    "for i in range(len(novice_files)):\n",
    "    novice_files[i] = novice_dir + novice_files[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse function that returns nested list of parsed commands based on session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_commands_per_session(command_list, parsed_list, files_list):\n",
    "    for file_path in tqdm(files_list):\n",
    "        file1 = open(file_path, encoding=\"ISO-8859-1\")\n",
    "        lines = file1.readlines()\n",
    "\n",
    "        command_sublist = []\n",
    "        parsed_sublist = []\n",
    "\n",
    "        for line in range(len(lines)):\n",
    "            \n",
    "            if re.match(re_start_filter, lines[line]) is not None:\n",
    "                if len(command_sublist) != 0 and len(parsed_sublist) != 0:\n",
    "                    command_list.append(copy.deepcopy(command_sublist))\n",
    "                    parsed_list.append(copy.deepcopy(parsed_sublist))\n",
    "\n",
    "\n",
    "                command_sublist = []\n",
    "                parsed_sublist = []\n",
    "            \n",
    "            if re.match(re_command_filter, lines[line]) is not None:\n",
    "                command_sublist.append(lines[line][2:-1])\n",
    "                \n",
    "                try:\n",
    "                    parts = list(bashlex.split(command_sublist[-1]))\n",
    "                    parsed_sublist.append(parts)\n",
    "                except Exception as inst:\n",
    "                    command_sublist.pop(-1)\n",
    "                    \n",
    "    \n",
    "    # Not necessary as list is created by ref parameter \n",
    "    return command_list\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that parses just by command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_commands(command_list, parsed_list, files_list):\n",
    "    for file_path in tqdm(files_list): \n",
    "        file1 = open(file_path, encoding=\"ISO-8859-1\")\n",
    "        lines = file1.readlines()\n",
    "\n",
    "        for line in range(len(lines)):\n",
    "            if re.match(re_command_filter, lines[line]) is not None:\n",
    "                command_list.append(lines[line][2:-1])\n",
    "                \n",
    "                try:\n",
    "                    parts = bashlex.parse(command_list[-1])\n",
    "                    parsed_list.append(parts)\n",
    "                except Exception as inst:\n",
    "                    command_list.pop(-1)\n",
    "\n",
    "    return command_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that parses commands and groups into subsets of `subset_size` meaning command chains are `subset_size` commands long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_commands_into_subsets(command_list, parsed_list, files_list, subset_size):\n",
    "    command_list = copy.deepcopy(parse_commands(command_list, parsed_list, files_list))\n",
    "\n",
    "    filter_escaped = lambda x: (x and x.isprintable())\n",
    "    command_list = list(filter(filter_escaped, command_list))\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range(0, len(command_list), subset_size):\n",
    "        result.append(command_list[i:i+subset_size])\n",
    "\n",
    "    command_list = result\n",
    "\n",
    "    return command_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:06<00:00,  7.77it/s]\n",
      "100%|██████████| 36/36 [00:03<00:00,  9.19it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.31it/s]\n",
      "100%|██████████| 56/56 [00:04<00:00, 13.33it/s]\n"
     ]
    }
   ],
   "source": [
    "scientist_commands = []\n",
    "experienced_commands = []\n",
    "non_programmers_commands = []\n",
    "novice_commands = []\n",
    "\n",
    "scientist_commands = parse_commands_per_session(scientist_commands, scientist_parsed, scientists_files)\n",
    "experienced_commands = parse_commands_per_session(experienced_commands, experienced_parsed, experienced_files)\n",
    "non_programmers_commands = parse_commands_per_session(non_programmers_commands, non_programmers_parsed, non_programmers_files)\n",
    "novice_commands = parse_commands_per_session(novice_commands, novice_parsed, novice_files)\n",
    "\n",
    "filter_empty = lambda x: (len(x) > 0)\n",
    "\n",
    "scientist_commands = list(filter(filter_empty, scientist_commands))\n",
    "experienced_commands = list(filter(filter_empty, experienced_commands))\n",
    "non_programmers_commands = list(filter(filter_empty, non_programmers_commands))\n",
    "novice_commands = list(filter(filter_empty, novice_commands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:13<00:00,  3.86it/s]\n",
      "100%|██████████| 36/36 [00:07<00:00,  5.13it/s]\n",
      "100%|██████████| 25/25 [00:03<00:00,  8.11it/s]\n",
      "100%|██████████| 56/56 [00:07<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "subset_size = 5\n",
    "\n",
    "scientist_commands = []\n",
    "experienced_commands = []\n",
    "non_programmers_commands = []\n",
    "novice_commands = []\n",
    "\n",
    "scientist_commands_subsets = parse_commands_into_subsets(scientist_commands, scientist_parsed, scientists_files, subset_size)\n",
    "experienced_commands_subsets = parse_commands_into_subsets(experienced_commands, experienced_parsed, experienced_files, subset_size)\n",
    "non_programmers_commands_subsets = parse_commands_into_subsets(non_programmers_commands, non_programmers_parsed, non_programmers_files, subset_size)\n",
    "novice_commands_subsets = parse_commands_into_subsets(novice_commands, novice_parsed, novice_files, subset_size)\n",
    "\n",
    "filter_empty = lambda x: (x is not None)\n",
    "\n",
    "scientist_commands_subsets = list(filter(filter_empty, scientist_commands_subsets))\n",
    "experienced_commands_subsets = list(filter(filter_empty, experienced_commands_subsets))\n",
    "non_programmers_commands_subsets = list(filter(filter_empty, non_programmers_commands_subsets))\n",
    "novice_commands_subsets = list(filter(filter_empty, novice_commands_subsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scientist_commands_subsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vapatel/Documents/Comp 991 - Prasun Research/bashcomplete/command prediction.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vapatel/Documents/Comp%20991%20-%20Prasun%20Research/bashcomplete/command%20prediction.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(scientist_commands_subsets))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vapatel/Documents/Comp%20991%20-%20Prasun%20Research/bashcomplete/command%20prediction.ipynb#ch0000013?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(experienced_commands_subsets))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vapatel/Documents/Comp%20991%20-%20Prasun%20Research/bashcomplete/command%20prediction.ipynb#ch0000013?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(non_programmers_commands_subsets))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scientist_commands_subsets' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(scientist_commands_subsets))\n",
    "print(len(experienced_commands_subsets))\n",
    "print(len(non_programmers_commands_subsets))\n",
    "print(len(novice_commands_subsets))\n",
    "\n",
    "print(scientist_commands_subsets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defunct, predicts next argument in command with this structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import Node\n",
    "\n",
    "def construct_graph_defunct(parsed_commands, command_dict = {}):\n",
    "\n",
    "    for cmd in parsed_commands:\n",
    "\n",
    "        cur_node = None\n",
    "\n",
    "        if command_dict.get(cmd[0]) is None:\n",
    "            cur_node = Node(command = cmd[0], frequency = 1)\n",
    "            command_dict[cmd[0]] = cur_node\n",
    "        else:\n",
    "            command_dict.get(cmd[0]).frequency += 1\n",
    "            cur_node = command_dict.get(cmd[0])\n",
    "\n",
    "        for i in range(1, len(cmd)):\n",
    "            child_node = None\n",
    "\n",
    "            if cur_node.children.get(cmd[i]) is None:\n",
    "                child_node = Node(cmd[i], 1)\n",
    "                cur_node.children[cmd[i]] = child_node\n",
    "            else:\n",
    "                cur_node.children.get(cmd[i]).frequency += 1\n",
    "                child_node = cur_node.children.get(cmd[i])\n",
    "            \n",
    "            cur_node = child_node\n",
    "        \n",
    "    return command_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph structure for next command. Use command list instead of bashlex output since we are comparing whole commands as nodes in a graph.\n",
    "\n",
    "Making command dict key the program (e.g. `cat`) and value the node with that program and have that nodes children be the full command. And then have the children of those nodes be determined by fuzzy matching. So a node can be a child to many parents if its fuzzy matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import Node\n",
    "\n",
    "def construct_graph(command_list, command_dict={}):\n",
    "\n",
    "    filter_empty = lambda x: (len(x) > 0)\n",
    "    cur_node = None\n",
    "    child_node = None\n",
    "    \n",
    "    for session in command_list:\n",
    "        # remove commands of length 0 ( not good to modify list within loop )\n",
    "        \n",
    "        session = list(filter(filter_empty, session))\n",
    "\n",
    "        try: \n",
    "            first_cmd = session[0]\n",
    "        except Exception as inst:\n",
    "            print(session)\n",
    "            continue\n",
    "\n",
    "        program = session[0].split()[0]\n",
    "\n",
    "        if command_dict.get(program) is None:\n",
    "            cur_node = Node(program=program, frequency=1)\n",
    "            command_dict[program] = cur_node \n",
    "        else:\n",
    "            cur_node = command_dict.get(program)\n",
    "            cur_node.frequency += 1\n",
    "\n",
    "        if cur_node.commands.get(first_cmd) is None:\n",
    "            cur_node.commands[first_cmd] = 1\n",
    "        else:\n",
    "            cur_node.commands[first_cmd] += 1\n",
    "\n",
    "        for cmd in range(1, len(session)):\n",
    "\n",
    "            if session[cmd].isprintable() is False:\n",
    "                break\n",
    "            else:\n",
    "                program = session[cmd].split()[0]\n",
    "\n",
    "            if cur_node.children.get(program) is None:\n",
    "                child_node = Node(program = program, frequency=1)\n",
    "                cur_node.children[program] = child_node\n",
    "            else:\n",
    "                child_node = cur_node.children.get(program)\n",
    "                child_node.frequency += 1\n",
    "            \n",
    "            if child_node.commands.get(session[cmd]) is None:\n",
    "                child_node.commands[session[cmd]] = 1\n",
    "            else:\n",
    "                child_node.commands[session[cmd]] += 1\n",
    "            \n",
    "            cur_node = child_node\n",
    "        \n",
    "                \n",
    "        \n",
    "    return command_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes list of commands and observes last 4 to predict 5th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(command_list, graph):\n",
    "    if len(command_list) == 0:\n",
    "        return None\n",
    "\n",
    "    commands = command_list[-3:-1]\n",
    "    previous_command = command_list[-1]\n",
    "\n",
    "    if len(commands) == 0:\n",
    "        return None\n",
    "\n",
    "    program = commands[0].split()[0]\n",
    "    \n",
    "    if graph.get(program) is None:\n",
    "        return None\n",
    "    else:\n",
    "        node = graph[program]\n",
    "\n",
    "    for command in commands[1:]:\n",
    "        program = command.split()[0]\n",
    "        if node.children.get(program) is not None:\n",
    "            node = node.children[program]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    return node.get_prediction(previous_command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def get_accuracy(command_subsets, print_fails = False):\n",
    "    split_ratio = .8\n",
    "    train_data, test_data = train_test_split(command_subsets, test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "    train_graph = construct_graph(train_data)\n",
    "\n",
    "    test_size = len(test_data)\n",
    "    correct = 0\n",
    "\n",
    "    for commands in test_data:\n",
    "        results = get_prediction(commands, train_graph)\n",
    "        \n",
    "        prev_correct = correct\n",
    "\n",
    "        if results is not None:\n",
    "            for result in results:\n",
    "                if fuzz.ratio(result[0], commands[-1]) > 75:\n",
    "                    correct += 1\n",
    "                    break\n",
    "        if prev_correct == correct and print_fails:\n",
    "            pp.pprint((\"results:\", results, \"expected:\" , commands[-1], \"command sequence:\", commands))\n",
    "                    \n",
    "\n",
    "    return '{:.2f}%'.format(100 * correct/test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cyverse command pull and parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"https://us-south.functions.appdomain.cloud/api/v1/web/ORG-UNC-dist-seed-james_dev/cyverse/get-cyverse-log\"\n",
    "query = {'body': {'log_type':'Bash', 'password': 'password', 'skip': '0', 'limit':'100'}}\n",
    "\n",
    "response_dict = {}\n",
    "\n",
    "def get_cyverse_commands():\n",
    "    for i in range(0, 1000, 100):\n",
    "        query = {'body': {'log_type':'Bash', 'password': 'password', 'skip': str(i), 'limit':'100'}}\n",
    "        response = requests.get(url, headers = {\"Content-Type\": \"application/json\"}, json = query)\n",
    "        print(i, response.status_code)\n",
    "        response_dict.update(response.json())\n",
    "        time.sleep(50)\n",
    "\n",
    "    return response_dict\n",
    "\n",
    "get_cyverse_commands()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyverse_commands = []\n",
    "\n",
    "for log in response_dict['logs']:\n",
    "    for command in log['log']['commands']:\n",
    "        if 'full_command' in command:\n",
    "            cyverse_commands.append(command['full_command'])\n",
    "\n",
    "len(cyverse_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cyverse_subsets(command_list, subset_size):\n",
    "    result = []\n",
    "\n",
    "    for i in range(0, len(command_list), subset_size):\n",
    "        result.append(command_list[i:i+subset_size])\n",
    "\n",
    "    return result\n",
    "\n",
    "cyverse_commands_subsets = parse_cyverse_subsets(cyverse_commands, 5)\n",
    "\n",
    "get_accuracy(cyverse_commands_subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colearning attempt with `scientist-1` and `scientist-2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_args(parsed_list):\n",
    "        filter_escaped = lambda x: (x and x.isprintable())\n",
    "\n",
    "        parsed_list_replaced = []\n",
    "        arg_replacements = [\"$\" + str(i) for i in range(100)]\n",
    "\n",
    "        exclude_chars = set(['|', '<', '>'])\n",
    "        \n",
    "        for lst in parsed_list:\n",
    "            lst = list(filter(filter_escaped, lst))\n",
    "            parsed_sublist_replaced = []\n",
    "            for command in range(len(lst)):\n",
    "                command_split = lst[command].split()\n",
    "                arg_counter = 0\n",
    "\n",
    "                for i in range(1, len(command_split)):\n",
    "                    if not command_split[i].startswith(\"-\") and command_split[i] not in exclude_chars:\n",
    "                        command_split[i] = arg_replacements[arg_counter]\n",
    "                        arg_counter += 1\n",
    "                \n",
    "                parsed_sublist_replaced.append(' '.join(command_split))\n",
    "                \n",
    "            parsed_list_replaced.append(parsed_sublist_replaced)\n",
    "\n",
    "        return parsed_list_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_colearn(command_subsets, test_set, print_fails = False):\n",
    "\n",
    "    train_graph = construct_graph(command_subsets)\n",
    "\n",
    "    test_size = len(test_set)\n",
    "    correct = 0\n",
    "\n",
    "    for commands in test_set:\n",
    "        results = get_prediction(commands, train_graph)\n",
    "        \n",
    "        prev_correct = correct\n",
    "\n",
    "        if results is not None:\n",
    "            for result in results:\n",
    "                if fuzz.partial_ratio(result[0], commands[-1]) > 85:\n",
    "                    correct += 1\n",
    "                    break\n",
    "        if prev_correct == correct and print_fails:\n",
    "            pp.pprint((\"results:\", results, \"expected:\" , commands[-1], \"command sequence:\", commands))\n",
    "                    \n",
    "\n",
    "    return '{:.2f}%'.format(100 * correct/test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "scientist_commands1 = parse_commands_into_subsets([], [], scientists_files[0:1], 5)\n",
    "scientist_commands1 = replace_args(scientist_commands1)\n",
    "\n",
    "scientist_commands2 = parse_commands_into_subsets([], [], scientists_files[1:2], 5)\n",
    "scientist_commands2 = replace_args(scientist_commands2)\n",
    "\n",
    "scientist_commands3 = parse_commands_into_subsets([], [], scientists_files[2:3], 5)\n",
    "scientist_commands3 = replace_args(scientist_commands3)\n",
    "\n",
    "scientist_commands10 = parse_commands_into_subsets([], [], scientists_files[0:10], 5)\n",
    "scientist_commands10 = replace_args(scientist_commands10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.72%\n",
      "94.57%\n",
      "95.79%\n",
      "94.57%\n",
      "95.79%\n",
      "96.72%\n",
      "96.72%\n",
      "96.75%\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy_colearn(scientist_commands1, scientist_commands2, print_fails=False))\n",
    "\n",
    "print(get_accuracy_colearn(scientist_commands2, scientist_commands1, print_fails=False))\n",
    "\n",
    "print(get_accuracy_colearn(scientist_commands1, scientist_commands3, print_fails=False))\n",
    "\n",
    "print(get_accuracy_colearn(scientist_commands3, scientist_commands1, print_fails=False))\n",
    "\n",
    "print(get_accuracy_colearn(scientist_commands2, scientist_commands3, print_fails=False))\n",
    "\n",
    "print(get_accuracy_colearn(scientist_commands3, scientist_commands2, print_fails=False))\n",
    "\n",
    "print(get_accuracy_colearn(scientist_commands10, scientist_commands2, print_fails=False))\n",
    "\n",
    "print(get_accuracy_colearn(scientist_commands2, scientist_commands10, print_fails=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_subsets_graph = parser.replace_args(parser.scientists_commands)\n",
    "science_subsets_graph = parser.parse_commands_into_subsets(science_subsets_graph, 5)\n",
    "graph = construct_graph(science_subsets_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mv $0 $1': 32,\n",
       " 'mv wancluster.c wancluster.c.old': 1,\n",
       " 'mv a.out dograms': 1,\n",
       " 'mv timeofda.h timeofday.h': 1,\n",
       " 'mv marbleli.h marblelist.h': 1,\n",
       " 'mv marblecl.h marbleclock.h': 1,\n",
       " 'mv a.out getim': 1,\n",
       " 'mv a.out header': 1,\n",
       " 'mv a.out subim': 1,\n",
       " 'mv a.out ../bin/shell': 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph[\"cc\"].children[\"mv\"].commands"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
