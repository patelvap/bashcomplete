{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Graph function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import Node\n",
    "\n",
    "def construct_graph(command_list, command_dict={}):\n",
    "\n",
    "    filter_empty = lambda x: (len(x) > 0)\n",
    "    cur_node = None\n",
    "    child_node = None\n",
    "    \n",
    "    for session in command_list:\n",
    "        # remove commands of length 0 ( not good to modify list within loop )\n",
    "        \n",
    "        session = list(filter(filter_empty, session))\n",
    "\n",
    "        try: \n",
    "            first_cmd = session[0]\n",
    "        except Exception as inst:\n",
    "            print(session)\n",
    "            continue\n",
    "\n",
    "        program = session[0].split()[0]\n",
    "\n",
    "        if command_dict.get(program) is None:\n",
    "            cur_node = Node(program=program, frequency=1)\n",
    "            command_dict[program] = cur_node \n",
    "        else:\n",
    "            cur_node = command_dict.get(program)\n",
    "            cur_node.frequency += 1\n",
    "\n",
    "        if cur_node.commands.get(first_cmd) is None:\n",
    "            cur_node.commands[first_cmd] = 1\n",
    "        else:\n",
    "            cur_node.commands[first_cmd] += 1\n",
    "\n",
    "        for cmd in range(1, len(session)):\n",
    "\n",
    "            if session[cmd].isprintable() is False:\n",
    "                break\n",
    "            else:\n",
    "                program = session[cmd].split()[0]\n",
    "\n",
    "            if cur_node.children.get(program) is None:\n",
    "                child_node = Node(program = program, frequency=1)\n",
    "                cur_node.children[program] = child_node\n",
    "            else:\n",
    "                child_node = cur_node.children.get(program)\n",
    "                child_node.frequency += 1\n",
    "            \n",
    "            if child_node.commands.get(session[cmd]) is None:\n",
    "                child_node.commands[session[cmd]] = 1\n",
    "            else:\n",
    "                child_node.commands[session[cmd]] += 1\n",
    "            \n",
    "            cur_node = child_node\n",
    "        \n",
    "                \n",
    "        \n",
    "    return command_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(command_list, graph, result_size=5):\n",
    "    if len(command_list) == 0:\n",
    "        return None\n",
    "\n",
    "    commands = command_list[:-1]\n",
    "    previous_command = command_list[-1]\n",
    "\n",
    "    if len(commands) == 0:\n",
    "        return None\n",
    "\n",
    "    program = commands[0].split()[0]\n",
    "    \n",
    "    if graph.get(program) is None:\n",
    "        return None\n",
    "    else:\n",
    "        node = graph[program]\n",
    "\n",
    "    for command in commands[1:]:\n",
    "        program = command.split()[0]\n",
    "        if node.children.get(program) is not None:\n",
    "            node = node.children[program]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    return node.get_prediction(previous_command, num_to_return=result_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def append_list(lst, results, commands):\n",
    "    # lst.append((\"results:\", results, \"expected:\", commands[-1], \"command sequence:\", commands))\n",
    "    lst.append({\"Results\": results, \"Expected\": commands[-1], \"Command Sequence\": commands})\n",
    "\n",
    "def get_accuracy(command_subsets, fail_list = [], succeed_list = [], correct_15_not_5 = [], print_fails = False):\n",
    "    train_data, test_data = train_test_split(command_subsets, test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "    train_graph = construct_graph(train_data)\n",
    "\n",
    "    test_size = len(test_data)\n",
    "\n",
    "    return_5 = 5\n",
    "    return_15 = 15\n",
    "\n",
    "    correct = 0\n",
    "    correct_with_15 = 0\n",
    "    first_prediction = 0\n",
    "    has_prediction = 0\n",
    "    incorrect = 0\n",
    "    none_count = 0\n",
    "\n",
    "    for commands in test_data:\n",
    "        results = get_prediction(commands, train_graph, return_5)\n",
    "        results_15 = get_prediction(commands, train_graph, return_15)\n",
    "        \n",
    "        prev_correct = correct\n",
    "\n",
    "        if results is not None:\n",
    "            has_prediction += 1\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                if fuzz.ratio(results[i][0], commands[-1]) > 85:\n",
    "                    correct += 1\n",
    "\n",
    "                    if i == 0:\n",
    "                        first_prediction += 1\n",
    "\n",
    "                    if correct <= 100:\n",
    "                        append_list(succeed_list, results, commands)\n",
    "\n",
    "                    break\n",
    "\n",
    "            if prev_correct == correct:\n",
    "                incorrect += 1\n",
    "\n",
    "            for i in range(len(results_15)):\n",
    "                if fuzz.ratio(results_15[i][0], commands[-1]) > 85:\n",
    "                    correct_with_15 += 1\n",
    "\n",
    "                    if correct != correct_with_15:\n",
    "                        append_list(correct_15_not_5, results_15, commands)\n",
    "\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "        if prev_correct == correct and print_fails:\n",
    "            append_list(fail_list, results, commands)                    \n",
    "\n",
    "    return 'Correct Proportion: {:.2f}% |\\n Correct in 15 not 5: {:.2f}% |\\n Has Prediction and is Correct: {:.2f}% |\\n Incorrect Proportion: {:.2f}% |\\n None Proportion: {:.2f}% |\\n First Prediction: {:.2f}%'.format(100 * correct/test_size, 100 * correct_with_15/test_size, 100 * correct/has_prediction, 100 * incorrect/test_size, 100 * none_count/test_size, 100 * first_prediction/test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:19<00:00,  2.67it/s]\n",
      "100%|██████████| 36/36 [00:11<00:00,  3.17it/s]\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.81it/s]\n",
      "100%|██████████| 56/56 [00:11<00:00,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from parse import Parser\n",
    "\n",
    "parser = Parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand pipes and replace args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nold, returning all potential commands - args not replaced\\n\\n91.19%\\n96.35%\\n90.31%\\n93.18%\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science = parser.filter_commands_with_pipe(parser.scientists_commands)\n",
    "experienced = parser.filter_commands_with_pipe(parser.experienced_commands)\n",
    "non = parser.filter_commands_with_pipe(parser.non_programmers_commands)\n",
    "novice = parser.filter_commands_with_pipe(parser.novice_commands)\n",
    "\n",
    "science_pipes = parser.expand_piped_commands(science)\n",
    "experienced_pipes = parser.expand_piped_commands(experienced)\n",
    "non_pipes = parser.expand_piped_commands(non)\n",
    "novice_pipes = parser.expand_piped_commands(novice)\n",
    "\n",
    "science_pipes_expand = parser.replace_arg_expanded_pipe(science_pipes)\n",
    "experienced_pipes_expand = parser.replace_arg_expanded_pipe(experienced_pipes)\n",
    "non_pipes_expand = parser.replace_arg_expanded_pipe(non_pipes)\n",
    "novice_pipes_expand = parser.replace_arg_expanded_pipe(novice_pipes)\n",
    "\n",
    "# print(get_accuracy(science_pipes))\n",
    "# print(get_accuracy(experienced_pipes))\n",
    "# print(get_accuracy(non_pipes))\n",
    "# print(get_accuracy(novice_pipes))\n",
    "\n",
    "\"\"\"\n",
    "old, returning all potential commands - args not replaced\n",
    "\n",
    "91.19%\n",
    "96.35%\n",
    "90.31%\n",
    "93.18%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Science pipes metrics:\n",
      " Correct Proportion: 83.86% |\n",
      " Correct in 15 not 5: 88.68% |\n",
      " Has Prediction and is Correct: 87.34% |\n",
      " Incorrect Proportion: 12.16% |\n",
      " None Proportion: 3.98% |\n",
      " First Prediction: 66.67% \n",
      "\n",
      "Experienced pipes metrics:\n",
      " Correct Proportion: 91.32% |\n",
      " Correct in 15 not 5: 94.06% |\n",
      " Has Prediction and is Correct: 93.02% |\n",
      " Incorrect Proportion: 6.85% |\n",
      " None Proportion: 1.83% |\n",
      " First Prediction: 74.43% \n",
      "\n",
      "Non programmers pipes metrics:\n",
      " Correct Proportion: 92.83% |\n",
      " Correct in 15 not 5: 95.93% |\n",
      " Has Prediction and is Correct: 93.37% |\n",
      " Incorrect Proportion: 6.59% |\n",
      " None Proportion: 0.58% |\n",
      " First Prediction: 76.74% \n",
      "\n",
      "Novice pipes metrics:\n",
      " Correct Proportion: 88.64% |\n",
      " Correct in 15 not 5: 90.91% |\n",
      " Has Prediction and is Correct: 92.86% |\n",
      " Incorrect Proportion: 6.82% |\n",
      " None Proportion: 4.55% |\n",
      " First Prediction: 52.27% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Science pipes metrics:\\n\", get_accuracy(science_pipes_expand), \"\\n\")\n",
    "print(\"Experienced pipes metrics:\\n\", get_accuracy(experienced_pipes_expand), \"\\n\")\n",
    "print(\"Non programmers pipes metrics:\\n\", get_accuracy(non_pipes_expand), \"\\n\")\n",
    "print(\"Novice pipes metrics:\\n\", get_accuracy(novice_pipes_expand), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "dataset_names = [\"Scientist pipes replaced\", \"Experienced pipes replaced\",\"Non programmer pipes replaced\", \"Novice pipes replaced\"]\n",
    "datasets = [science_pipes_expand, experienced_pipes_expand, non_pipes_expand, novice_pipes_expand]\n",
    "\n",
    "for i in tqdm(range(len(datasets))):\n",
    "    fail_list = []\n",
    "    succeed_list = []\n",
    "    correct_15_not_5 = []\n",
    "\n",
    "    get_accuracy(datasets[i], fail_list=fail_list, succeed_list=succeed_list, correct_15_not_5=correct_15_not_5, print_fails=True)\n",
    "\n",
    "    with open(\"fails/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "        file_object.write(pp.pformat(fail_list))\n",
    "    \n",
    "    with open(\"successes/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "        file_object.write(pp.pformat(succeed_list))\n",
    "\n",
    "    with open(\"correct_with_15/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "        file_object.write(pp.pformat(correct_15_not_5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save not matching or none result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:58<00:53, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:59<00:00,  7.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "dataset_names = [\"Scientist replaced\", \"Experienced replaced\", \"Non programmer replaced\", \"Novice replaced\"]\n",
    "datasets = [science_replaced, experienced_replaced, non_replaced, novice_replaced]\n",
    "\n",
    "# for i in tqdm(range(len(datasets))):\n",
    "#     fail_list = []\n",
    "#     succeed_list = []\n",
    "#     correct_15_not_5 = []\n",
    "\n",
    "#     get_accuracy(datasets[i], fail_list=fail_list, succeed_list=succeed_list, correct_15_not_5=correct_15_not_5, print_fails=True)\n",
    "\n",
    "#     with open(\"./fails/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "#         file_object.write(pp.pformat(fail_list))\n",
    "    \n",
    "#     with open(\"./successes/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "#         file_object.write(pp.pformat(succeed_list))\n",
    "\n",
    "#     with open(\"./correct_with_15/\" + dataset_names[i] + \".txt\", \"w\") as file_object:\n",
    "#         file_object.write(pp.pformat(correct_15_not_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training graphs to JSON files. Files are 48.9 MB and very hard to open.\n",
    "\n",
    "Instead of this, we can just save it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:09<00:08,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:16<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import jsonpickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "dataset_names = [\"Scientist replaced\", \"Experienced replaced\", \"Non programmer replaced\", \"Novice replaced\", \"Scientist pipes replaced\", \"Experienced pipes replaced\",\"Non programmer pipes replaced\", \"Novice pipes replaced\"]\n",
    "datasets = [science_session, experienced_session, non_session, novice_session, science_pipes_expand, experienced_pipes_expand, non_pipes_expand, novice_pipes_expand]\n",
    "\n",
    "train_graphs = []\n",
    "test_graphs = []\n",
    "\n",
    "for i in tqdm(range(len(datasets))):\n",
    "    train_data, test_data = train_test_split(datasets[i], test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "    train_graph = construct_graph(train_data)\n",
    "    test_graph = construct_graph(test_data)\n",
    "\n",
    "    train_graphs.append(train_graph)\n",
    "    test_graphs.append(test_graph)\n",
    "\n",
    "    train_object = jsonpickle.encode(train_graph[\"cd\"])\n",
    "    test_object = jsonpickle.encode(test_graph[\"cd\"])\n",
    "\n",
    "    with open(\"./train_graphs/\" + dataset_names[i] + \" train.json\", \"w\") as file_object:\n",
    "        file_object.write(train_object)\n",
    "\n",
    "    with open (\"./test_graphs/\" + dataset_names[i] + \" test.json\", \"w\") as file_object:\n",
    "        file_object.write(test_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliding window subsets and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:17<00:00,  3.05it/s]\n",
      "100%|██████████| 36/36 [00:09<00:00,  3.75it/s]\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.43it/s]\n",
      "100%|██████████| 56/56 [00:10<00:00,  5.11it/s]\n"
     ]
    }
   ],
   "source": [
    "science_session = parser.parse_commands_per_session(parser.scientists_files)\n",
    "science_session = parser.parse_commands_into_subsets_sliding_window(science_session, 5)\n",
    "science_session = parser.replace_args_nested(science_session)\n",
    "\n",
    "experienced_session = parser.parse_commands_per_session(parser.experienced_files)\n",
    "experienced_session = parser.parse_commands_into_subsets_sliding_window(experienced_session, 5)\n",
    "experienced_session = parser.replace_args_nested(experienced_session)\n",
    "\n",
    "non_session = parser.parse_commands_per_session(parser.non_programmers_files)\n",
    "non_session = parser.parse_commands_into_subsets_sliding_window(non_session, 5)\n",
    "non_session = parser.replace_args_nested(non_session)\n",
    "\n",
    "novice_session = parser.parse_commands_per_session(parser.novice_files)\n",
    "novice_session = parser.parse_commands_into_subsets_sliding_window(novice_session, 5)\n",
    "novice_session = parser.replace_args_nested(novice_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist session:\n",
      " Correct Proportion: 86.00% |\n",
      " Correct in 15 not 5: 94.86% |\n",
      " Has Prediction and is Correct: 86.04% |\n",
      " Incorrect Proportion: 13.95% |\n",
      " None Proportion: 0.05% |\n",
      " First Prediction: 60.97%\n",
      "Experienced session:\n",
      " Correct Proportion: 88.93% |\n",
      " Correct in 15 not 5: 96.05% |\n",
      " Has Prediction and is Correct: 88.97% |\n",
      " Incorrect Proportion: 11.02% |\n",
      " None Proportion: 0.05% |\n",
      " First Prediction: 65.22%\n",
      "Non programmer session:\n",
      " Correct Proportion: 86.34% |\n",
      " Correct in 15 not 5: 94.22% |\n",
      " Has Prediction and is Correct: 86.37% |\n",
      " Incorrect Proportion: 13.63% |\n",
      " None Proportion: 0.04% |\n",
      " First Prediction: 60.92%\n",
      "Novice session:\n",
      " Correct Proportion: 90.79% |\n",
      " Correct in 15 not 5: 96.89% |\n",
      " Has Prediction and is Correct: 90.85% |\n",
      " Incorrect Proportion: 9.14% |\n",
      " None Proportion: 0.06% |\n",
      " First Prediction: 66.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"Scientist session:\\n\", get_accuracy(science_session))\n",
    "print(\"Experienced session:\\n\", get_accuracy(experienced_session))\n",
    "print(\"Non programmer session:\\n\", get_accuracy(non_session))\n",
    "print(\"Novice session:\\n\", get_accuracy(novice_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.54it/s]\n",
      "100%|██████████| 7/7 [00:02<00:00,  3.44it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n",
      "100%|██████████| 11/11 [00:02<00:00,  4.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "import math\n",
    "\n",
    "subset_size = 5\n",
    "\n",
    "science_session_sample = parser.parse_commands_per_session(sample(parser.scientists_files, math.floor(0.2 * len(parser.scientists_files))))\n",
    "science_session_sample = parser.parse_commands_into_subsets_sliding_window(science_session_sample, 5)\n",
    "science_session_sample = parser.replace_args_nested(science_session_sample)\n",
    "\n",
    "experienced_session_sample = parser.parse_commands_per_session(sample(parser.experienced_files, math.floor(0.2 * len(parser.experienced_files))))\n",
    "experienced_session_sample = parser.parse_commands_into_subsets_sliding_window(experienced_session_sample, 5)\n",
    "experienced_session_sample = parser.replace_args_nested(experienced_session_sample)\n",
    "\n",
    "non_session_sample = parser.parse_commands_per_session(sample(parser.non_programmers_files, math.floor(0.2 * len(parser.non_programmers_files))))\n",
    "non_session_sample = parser.parse_commands_into_subsets_sliding_window(non_session_sample, 5)\n",
    "non_session_sample = parser.replace_args_nested(non_session_sample)\n",
    "\n",
    "novice_session_sample = parser.parse_commands_per_session(sample(parser.novice_files, math.floor(0.2 * len(parser.novice_files))))\n",
    "novice_session_sample = parser.parse_commands_into_subsets_sliding_window(novice_session_sample, 5)\n",
    "novice_session_sample = parser.replace_args_nested(novice_session_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist session:\n",
      " Correct Proportion: 87.77% |\n",
      " Correct in 15 not 5: 96.35% |\n",
      " Has Prediction and is Correct: 87.77% |\n",
      " Incorrect Proportion: 12.23% |\n",
      " None Proportion: 0.00% |\n",
      " First Prediction: 65.11%\n",
      "Experienced session:\n",
      " Correct Proportion: 91.32% |\n",
      " Correct in 15 not 5: 97.49% |\n",
      " Has Prediction and is Correct: 91.33% |\n",
      " Incorrect Proportion: 8.67% |\n",
      " None Proportion: 0.01% |\n",
      " First Prediction: 65.74%\n",
      "Non programmer session:\n",
      " Correct Proportion: 81.75% |\n",
      " Correct in 15 not 5: 91.94% |\n",
      " Has Prediction and is Correct: 81.75% |\n",
      " Incorrect Proportion: 18.25% |\n",
      " None Proportion: 0.00% |\n",
      " First Prediction: 59.64%\n",
      "Novice session:\n",
      " Correct Proportion: 93.18% |\n",
      " Correct in 15 not 5: 98.21% |\n",
      " Has Prediction and is Correct: 93.18% |\n",
      " Incorrect Proportion: 6.82% |\n",
      " None Proportion: 0.00% |\n",
      " First Prediction: 70.18%\n"
     ]
    }
   ],
   "source": [
    "print(\"Scientist session:\\n\", get_accuracy(science_session_sample))\n",
    "print(\"Experienced session:\\n\", get_accuracy(experienced_session_sample))\n",
    "print(\"Non programmer session:\\n\", get_accuracy(non_session_sample))\n",
    "print(\"Novice session:\\n\", get_accuracy(novice_session_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects are 84 MB instead of 53 MB with sampling 10% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "dataset_names = [\"Scientist replaced\", \"Experienced replaced\", \"Non programmer replaced\", \"Novice replaced\"]\n",
    "datasets = [science_session, experienced_session, non_session, novice_session]\n",
    "\n",
    "train_graphs = []\n",
    "test_graphs = []\n",
    "\n",
    "# for i in tqdm(range(len(datasets))):\n",
    "#     train_data, test_data = train_test_split(datasets[i], test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "#     train_graph = construct_graph(train_data)\n",
    "#     print(\"Train graph\", sys.getsizeof(train_graph)/1000000.0)\n",
    "#     test_graph = construct_graph(test_data)\n",
    "#     print(\"Test graph\", sys.getsizeof(test_graph)/1000000.0)\n",
    "\n",
    "#     train_graphs.append(train_graph)\n",
    "#     test_graphs.append(test_graph)\n",
    "\n",
    "#     train_object = jsonpickle.encode(train_graph)\n",
    "#     print(\"Train JSON\", sys.getsizeof(train_object)/1000000.0)\n",
    "#     test_object = jsonpickle.encode(test_graph)\n",
    "#     print(\"Test JSON\", sys.getsizeof(test_object)/1000000.0)\n",
    "\n",
    "#     with open(\"./train_graphs/\" + dataset_names[i] + \" train.json\", \"w\") as file_object:\n",
    "#         file_object.write(train_object)\n",
    "\n",
    "#     with open (\"./test_graphs/\" + dataset_names[i] + \" test.json\", \"w\") as file_object:\n",
    "#         file_object.write(test_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Reduce to see most common how often command sequences occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce(parsed_nested_list):\n",
    "    reduced = dict()\n",
    "\n",
    "    for command_seq in parsed_nested_list:\n",
    "        command_seq = tuple(command_seq)\n",
    "\n",
    "        if command_seq in reduced:\n",
    "            reduced[command_seq] += 1\n",
    "        else:\n",
    "            reduced[command_seq] = 1\n",
    "\n",
    "    return reduced\n",
    "\n",
    "def len_n_commands(session_dict, command_len):\n",
    "    len_n_dict = dict()\n",
    "\n",
    "    for command_seq, freq in session_dict.items():\n",
    "        if freq > 1 and len(command_seq) == command_len:\n",
    "            len_n_dict[command_seq] = freq\n",
    "    \n",
    "    return len_n_dict\n",
    "\n",
    "def popular_seq_by_user(file_name, command_len, num_to_return=5):\n",
    "    if type(file_name) != list:\n",
    "        file_name = [file_name]\n",
    "\n",
    "    session_subsets = parser.parse_commands_per_session(file_name)\n",
    "    session_subsets = parser.parse_commands_into_subsets_sliding_window(session_subsets, 5)\n",
    "    session_subsets = parser.replace_args_nested(session_subsets)\n",
    "\n",
    "    session_dict = map_reduce(session_subsets)\n",
    "\n",
    "    session_dict = len_n_commands(session_dict, command_len)\n",
    "\n",
    "    return sorted(session_dict.items(), key=lambda item : item[1], reverse=True)[:num_to_return]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save most common commands of length `command_len` to file. Uses parse commands by subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "files = [parser.scientists_files, parser.experienced_files, parser.non_programmers_files, parser.novice_files]\n",
    "dataset_name = [\"scientists\", \"experienced\", \"non_programmers\", \"novice\"]\n",
    "\n",
    "command_len = 2\n",
    "\n",
    "for file_list in range(len(files)):\n",
    "    for file in files[file_list]:\n",
    "        with open(\"./highest_freq_len_5/\" + dataset_name[file_list] + \".txt\", \"a\") as file_object:\n",
    "            # file_object.write(pp.pformat([file.split('/')[3], popular_seq_by_user(file)]))\n",
    "            file_name = file.split('/')[3]\n",
    "            seq_freq = popular_seq_by_user(file, command_len)\n",
    "            seq_freq_lst = []\n",
    "            \n",
    "            for seq, freq in seq_freq:\n",
    "                seq_freq_lst.append(str(seq) + \": \" + str(freq) + '\\n')\n",
    "\n",
    "            line = \"{}:\\n\\t {}\\n\".format(file_name, ', '.join(seq_freq_lst))\n",
    "\n",
    "            file_object.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Top 10 by type of User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:10<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (('cd $0', 'ls', 'cd $0', 'ls'), 1016),\n",
      "    (('ls', 'cd $0', 'ls', 'cd $0'), 569),\n",
      "    (('average', 'average', 'average', 'average'), 443),\n",
      "    (('lpq -Pip', 'lpq -Pip', 'lpq -Pip', 'lpq -Pip'), 191),\n",
      "    (('cd $0', 'cd $0', 'ls', 'cd $0'), 189)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (('cd $0', 'ls', 'cd $0', 'ls'), 668),\n",
      "    (('ls', 'cd $0', 'ls', 'cd $0'), 467),\n",
      "    (('cd $0', 'cd $0', 'ls', 'cd $0'), 170),\n",
      "    (('jobs', 'jobs', 'jobs', 'jobs'), 164),\n",
      "    (('ls', 'cd $0', 'cd $0', 'ls'), 134)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (('emacs $0', 'emacs $0', 'emacs $0', 'emacs $0'), 194),\n",
      "    (('cd $0', 'ls', 'cd $0', 'ls'), 151),\n",
      "    (('rm $0', 'rm $0', 'rm $0', 'rm $0'), 113),\n",
      "    (('ls', 'cd $0', 'ls', 'e $0'), 109),\n",
      "    (('ls', 'cd $0', 'ls', 'cd $0'), 101)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:06<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (('umacs $0', 'pix $0', 'umacs $0', 'pix $0'), 4536),\n",
      "    (('pix $0', 'umacs $0', 'pix $0', 'umacs $0'), 4079),\n",
      "    (('pix $0', 'umacs $0', 'pix $0', 'pix $0'), 865),\n",
      "    (('pix $0', 'pix $0', 'umacs $0', 'pix $0'), 813),\n",
      "    (('pix $0', 'pix $0', 'pix $0', 'pix $0'), 757)]\n"
     ]
    }
   ],
   "source": [
    "files = [parser.scientists_files, parser.experienced_files, parser.non_programmers_files, parser.novice_files]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    pp.pprint(popular_seq_by_user(files[i], 2, num_to_return=6)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
